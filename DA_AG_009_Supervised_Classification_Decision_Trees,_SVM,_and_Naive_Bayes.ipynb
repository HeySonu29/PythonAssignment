{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6f581f4d",
      "metadata": {
        "id": "6f581f4d"
      },
      "source": [
        "# DA-AG-009 — Supervised Classification: Decision Trees, SVM, and Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d9a1f8b",
      "metadata": {
        "id": "5d9a1f8b"
      },
      "source": [
        "## Q1. What is Information Gain, and how is it used in Decision Trees?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de53fee4",
      "metadata": {
        "id": "de53fee4"
      },
      "source": [
        "**Answer:**  \n",
        "Information Gain (IG) measures the reduction in entropy after splitting data on an attribute.  \n",
        "The attribute with the highest IG is chosen for splitting.\n",
        "\n",
        "\\[ IG(S, A) = Entropy(S) - \\sum_v \\frac{|S_v|}{|S|} Entropy(S_v) \\]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c16c33",
      "metadata": {
        "id": "f7c16c33"
      },
      "source": [
        "## Q2. What is the difference between Gini Impurity and Entropy?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745884e9",
      "metadata": {
        "id": "745884e9"
      },
      "source": [
        "| Measure | Formula | Range | Remarks |\n",
        "|----------|----------|--------|----------|\n",
        "| **Gini Impurity** | 1 - Σ p_i² | 0–0.5 | Faster, default in sklearn |\n",
        "| **Entropy** | -Σ p_i log₂ p_i | 0–1 | From info theory, more interpretable |\n",
        "\n",
        "Both measure node impurity; **Gini** is simpler and slightly faster.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24a67869",
      "metadata": {
        "id": "24a67869"
      },
      "source": [
        "## Q3. What is Pre-Pruning in Decision Trees?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e44ced8a",
      "metadata": {
        "id": "e44ced8a"
      },
      "source": [
        "**Answer:**  \n",
        "Pre-pruning stops tree growth early using parameters like `max_depth`, `min_samples_split`, or `min_impurity_decrease` to prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ffa877c",
      "metadata": {
        "id": "3ffa877c"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "clf = DecisionTreeClassifier(max_depth=3, min_samples_split=5)\n",
        "clf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735946d8",
      "metadata": {
        "id": "735946d8"
      },
      "source": [
        "## Q4. Train a Decision Tree using Gini Impurity and print feature importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef777357",
      "metadata": {
        "id": "ef777357"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import pandas as pd\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "model = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Feature Importances\n",
        "pd.DataFrame({'Feature': data.feature_names, 'Importance': model.feature_importances_})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74670ea5",
      "metadata": {
        "id": "74670ea5"
      },
      "source": [
        "## Q5. What is a Support Vector Machine (SVM)?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d76da960",
      "metadata": {
        "id": "d76da960"
      },
      "source": [
        "**Answer:**  \n",
        "SVM finds the optimal hyperplane separating classes with maximum margin. Effective for high-dimensional data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45f53ee6",
      "metadata": {
        "id": "45f53ee6"
      },
      "source": [
        "## Q6. What is the Kernel Trick in SVM?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "708ed429",
      "metadata": {
        "id": "708ed429"
      },
      "source": [
        "**Answer:**  \n",
        "Kernel Trick maps non-linear data to higher dimensions (using RBF, polynomial, etc.) for linear separation in transformed space."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e3d2a81",
      "metadata": {
        "id": "3e3d2a81"
      },
      "source": [
        "## Q7. Train two SVMs (Linear and RBF) on the Wine dataset and compare accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7f8acb6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7f8acb6",
        "outputId": "f89dd125-453c-4332-efbe-56e329b3f2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Kernel Accuracy: 0.9814814814814815\n",
            "RBF Kernel Accuracy: 0.7592592592592593\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "wine = load_wine()\n",
        "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.3, random_state=42)\n",
        "\n",
        "svm_linear = SVC(kernel='linear')\n",
        "svm_rbf = SVC(kernel='rbf')\n",
        "\n",
        "svm_linear.fit(X_train, y_train)\n",
        "svm_rbf.fit(X_train, y_train)\n",
        "\n",
        "acc_linear = accuracy_score(y_test, svm_linear.predict(X_test))\n",
        "acc_rbf = accuracy_score(y_test, svm_rbf.predict(X_test))\n",
        "\n",
        "print('Linear Kernel Accuracy:', acc_linear)\n",
        "print('RBF Kernel Accuracy:', acc_rbf)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ce12948",
      "metadata": {
        "id": "5ce12948"
      },
      "source": [
        "## Q8. What is the Naïve Bayes classifier, and why is it called 'Naïve'?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfbb6176",
      "metadata": {
        "id": "dfbb6176"
      },
      "source": [
        "**Answer:**  \n",
        "Naïve Bayes applies Bayes’ Theorem assuming **feature independence** (hence “naïve”).  \n",
        "It’s fast, simple, and effective for text classification and spam detection.\n",
        "\n",
        "\\[ P(C|X) = \\frac{P(X|C) P(C)}{P(X)} \\]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8c1d7e3",
      "metadata": {
        "id": "e8c1d7e3"
      },
      "source": [
        "## Q9. Differences between Gaussian, Multinomial, and Bernoulli Naïve Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78c72275",
      "metadata": {
        "id": "78c72275"
      },
      "source": [
        "| Type | Data Type | Example Use |\n",
        "|------|------------|--------------|\n",
        "| **GaussianNB** | Continuous | Iris, medical data |\n",
        "| **MultinomialNB** | Count data | Text, word frequencies |\n",
        "| **BernoulliNB** | Binary features | Binary word presence |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54771747",
      "metadata": {
        "id": "54771747"
      },
      "source": [
        "## Q10. Train Gaussian Naïve Bayes on Breast Cancer dataset and evaluate accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec805041",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec805041",
        "outputId": "06d79981-4e59-40d5-8e06-03ef24233f28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9415204678362573\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.3, random_state=42)\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "pred = model.predict(X_test)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9514361b",
      "metadata": {
        "id": "9514361b"
      },
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}